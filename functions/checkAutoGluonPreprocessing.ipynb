{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzUz7d-gjmb6"
      },
      "outputs": [],
      "source": [
        "def checkAutoGluonPreprocessing(result_list_acc, result_list_roc, train_data, test_data, result_log_file = 'result_log_File.txt',time_limit = 10, label = \"class\",subsample_size = 500):\n",
        "   ## result_list_acc, result_list_roc - empty lists that will contain the results (accuracy and auc scores), result_log_file - the file in which there will be information about preprocessing,\n",
        "   ## time_limit - the time limit of training, label - the name of target variable\n",
        "    from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "    #data,y,_,_ = openml.datasets.get_dataset(data_openML_Id).get_data(dataset_format=\"dataframe\")\n",
        "\n",
        "    #train_data, test_data = prepare_data(data)\n",
        "    print(train_data)\n",
        "    #train_data = train_data.sample(n=200, random_state=0)\n",
        "    #train_data.head()\n",
        "\n",
        "    print(\"Summary of class variable: \\n\", )\n",
        "    #brzydkie rozwiazanie brzydkiego błędu\n",
        "    import random\n",
        "    import string\n",
        "    randomString = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
        "\n",
        "    save_path = 'ggModels-predictClass'\n",
        "    tmp_log_file = '.\\ggModels-predictClass\\logs\\\\'+randomString+'predictor_log.txt'\n",
        "\n",
        "    predictor = TabularPredictor(label=label, path=save_path,verbosity=2,log_to_file=True,log_file_path=tmp_log_file).fit(train_data,time_limit=time_limit)\n",
        "\n",
        "\n",
        "    import os\n",
        "    # if os.path.exists(result_log_file):\n",
        "    #     os.remove(result_log_file)\n",
        "    result_file = open(result_log_file,\"w\")\n",
        "    result_file.truncate(0)\n",
        "    write_flag = False\n",
        "    StartSubstring = \"Fitting AutoMLPipelineFeatureGenerator\"\n",
        "    EndSubstring = \"User-specified model hyperparameters to be fit\"\n",
        "\n",
        "    logs = open(tmp_log_file,\"r\")\n",
        "\n",
        "    for line in logs:\n",
        "        if line.startswith(StartSubstring):\n",
        "            write_flag=True\n",
        "        if line.startswith(EndSubstring):\n",
        "            write_flag=False\n",
        "        if(write_flag==True):\n",
        "            result_file.write(line)\n",
        "\n",
        "\n",
        "    logs.close()\n",
        "    result_file.close()\n",
        "    t = open(tmp_log_file,\"w\")\n",
        "    t.truncate(0)\n",
        "    t.close()\n",
        "    os.remove(tmp_log_file)\n",
        "\n",
        "    results_dict = predictor.evaluate(test_data)\n",
        "\n",
        "    performance_acc = list(results_dict.values())[0]     # robimy to w taki sposób, bo predictor.evaluate zwraca słownik w którym klucze to nazwy różnych miar a wartości to te miary\n",
        "    result_list_acc.append(performance_acc)\n",
        "\n",
        "    performance_roc = list(results_dict.values())[3]\n",
        "    result_list_roc.append(performance_roc)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}